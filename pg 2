import gensim.downloader as api
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# Load pre-trained Word2Vec model (Google News)
print("Loading model... (This may take a while)")
model = api.load("word2vec-google-news-300")
print("Model loaded!")

# Select 10 words from the Technology domain
tech_words = ["computer", "algorithm", "software", "hardware", "AI",
              "cloud", "database", "network", "cybersecurity", "encryption"]

# Get their word vectors (handling missing words)
word_vectors = []
valid_words = []

for word in tech_words:
    try:
        word_vectors.append(model[word])
        valid_words.append(word)
    except KeyError:
        print(f"'{word}' not in vocabulary.")

# Convert to NumPy array
word_vectors = np.array(word_vectors)

# Perform PCA to reduce to 2D
pca = PCA(n_components=2)
reduced_vectors = pca.fit_transform(word_vectors)

# Plot the words in 2D
plt.figure(figsize=(10, 8))
for word, (x, y) in zip(valid_words, reduced_vectors):
    plt.scatter(x, y)
    plt.text(x + 0.02, y + 0.02, word, fontsize=12)
plt.title("2D Visualization of Technology Word Embeddings")
plt.xlabel("PCA Component 1")
plt.ylabel("PCA Component 2")
plt.grid()
plt.show()
def find_similar_words(word):
    try:
        similar_words = model.most_similar(word, topn=5)
        print(f"\n5 words similar to '{word}':")
        for w, score in similar_words:
            print(f"{w}: {score:.4f}")
    except KeyError:
        print(f"'{word}' not found in the vocabulary.")

find_similar_words("AI")
